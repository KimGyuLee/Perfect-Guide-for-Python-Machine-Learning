NLP (Natural Language Processing)
----------------------------------------------------------
- 인간의 언어를 이해하고 해석하는데 더 중점을 두고 기술이 발전해왔다.  
- NLP 기술의 발전으로 텍스트 분석도 더욱 정교하게 발전했다.  

텍스트 분석 주요 영역
----------------------------------------------------------
- 텍스트 분석은 머신러닝, 언어 이해, 통계 등을 활용해 모델을 수립하고 정보를 추출해 비즈니스 인텔리전스나 예측 분석 등의 분석 작업에 주로 사용 된다.

#### 1. 텍스트 분류  
– 문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법을 통칭한다. 
- 예를 들어 특정 신문 기사 내용이 연애/정치/사회/문화 중 어떤 카테고리에 속하는지 자동으로 분류하거나 스팸 메일 검출 같은 프로그램이 이에 속한다. 지도학습을 적용한다.

#### 2. 감성 분석  
– 텍스트에서 나타나는 감정/판단/믿음/의견/기분 등의 주관적인 요소를 분석하는 기법을 총칭한다.
- 소셜 미디어 감성 분석, 영화나 제품에 대한 긍정 또는 부정 리뷰, 여론조사 의견 분석 등의 다양한 영역에서 활용된다. 
- 지도학습 방법뿐만 아니라 비지도학습을 이용해 적용할 수 있다. 지도학습으로 한다면 텍스트 분류와 유사하다고 볼 수 있다. 비지도 학습으로는 감성 딕셔너리라는 것이 있는데, 딕셔너리에 적용하여 단어를 긍정 감성 0.6, 부정 감성 0.4과 같이 나타낼 수 있다. 영어로 되어있으며 한글 감성분석 딕셔너리는 잘 활용되지 않는다.

#### 3. 텍스트 요약   
– 텍스트 내에서 중요한 주제나 중심 사상을 추출하는 기법이다. 대표적으로 토픽 모델링이 있다.

#### 4. 텍스트 군집화와 유사도 측정   
– 비슷한 유형의 문서에 대해 군집화를 수행하는 기법이다. 텍스트 분류를 비지도학습으로 수행하는 방법의 일환으로 사용될 수 있다. 유사도 측정 역시 문서들 간의 유사도를 측정해 비슷한 문서끼리 모을 수 있는 방법이다.

텍스트 분석 머신러닝 수행 프로세스
----------------------------------------------------------
- 피처를 가진 데이터가 필요하다. 피처가 있어야 피처를 가지고 패턴을 찾는 머신러닝 학습/예측/평가가 가능하다.
- 텍스트를 피처로 만드는 것을 feature vectorization이라고 한다.
- Bag of words는 모든 단어를 피처로 만드는 것이다. 그 단어가 뜻하는 것을 보통 피처 값으로 만드는데, 주로 이 단어가 몇 번 나왔는지 또는 다른 정규화 값으로 이 단어가 의미하는 것을 값으로 나타낸다.
- 텍스트를 피처 벡터라이제이션 전에 정제한 후, 피처 벡터라이제이션을 수행한다. 벡터로 만들면 머신러닝으로 학습할 수 있다.

파이썬 기반의 NLP, 텍스트 분석 패키지
----------------------------------------------------------
- 분석 패키지에는 NLTK, genism, spaCy가 있다.
- NLTK (National Language Toolkit for Python): 파이썬의 가장 대표적인 NLP 패키지이다. NLP의 거의 모든 영역을 커버하고 있다. 그러나 수행 속도 측면에서 아쉬운 부분이 있어서 실제 대량의 데이터 기반에서는 제대로 활용되지 못하고 있다. 아카데믹하며 기업에서 활용하기에 무리가 있다.
- Gensim: 토픽 모델링 분야에서 가장 두각을 나타내는 패키지이다. Word2Vec 구현 등의 기능이 있다.
- SpaCy: 뛰어난 수행 성능으로 최근 가장 주목받고 있다.

텍스트 전처리 (= 텍스트 정규화) feature vectorization 전 단계
----------------------------------------------------------
- 클렌징 : 텍스트에서 분석에 오히려 방해가 되는 불필요한 문자, 기호 등을 사전에 제거하는 작업이다. 예를 들어 웹에서 스크랩핑 했을 경우, HTML, XML 태그나 특정 기호 등을 사전에 제거한다.
- 토큰화 : 문장 토큰화 (잘 안 쓰인다. 보통은 단어 토큰화), 단어 토큰화, n-gram
- 필터링/스톱워드(a, the, is, will 등) 제거/철자 수정 : 불필요한 단어나 분석에 큰 의미가 없는 단어 (a, the, is, will 등), 잘못된 철자를 수정한다.
- Stemming/Lemmatization : 어근(단어 원형) 추출, Lemmatization이 Stemming 보다 정교하고 의미론적 기반에서 단어 원형을 찾아 준다. (ex. 3인칭단수 s, 과거형 ed, 비교형 er에서 원형 추출) Ex. Lemmatization: Amusing -> amuse

N-gram
----------------------------------------------------------
-	문장을 개별 단어 별로 하나씩 토큰화 할 경우 문맥적인 의미는 무시될 수밖에 없다. 이러한 문제를 조금이라도 해결해 보고자 도입된 것이다.
-	연속된 N개의 단어를 하나의 토큰화 단위로 분리해 내는 것이다. N개 단어 크기 윈도우를 만들어 문장의 처음부터 오른쪽으로 움직이면서 토큰화를 수행한다.
-	예를 들어 ‘Agent Smith knocks the door’를 2-gram으로 만들면 (Agent, Smith), (Smith, knocks) … 와 같이 연속적으로 2개의 단어들을 순차적으로 이동하면서 단어들을 토큰화한다.

