# Regression

## Intro
회귀는 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법이다. 회귀는 지도 학습에서 가장 많이 활용되며, 주로 수치 데이터를 활용하는 기업의 데이터 분석에서 많이 사용된다.
머신러닝 회귀 예측의 핵심은 주어진 피처(독립 변수)와 결정 값 데이터(종속 변수) 기반에서 학습을 통해 최적의 회귀 계수를 찾아내는 것이다.

회귀는 회귀계수가 선형이면 선형 회귀, 선형이 아니면 비선형 회귀로 분류된다. 또한, 독립변수의 개수가 한 개이면 단일 회귀, 여러 개이면 다중 회귀로 나뉜다. 일반적으로 정형 데이터일 경우, 선형 회귀가 비선형회귀보다 예측 성능이 좋다.

최적의 회귀 모델을 만든다는 것은 전체 데이터의 잔차(오류 값) 합이 최소가 되는 모델을 만드는 것이다. 동시에 오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다는 의미이기도 하다.

Classification은 Category 값 (이산값)을 결과값으로 반환하고, Regression은 숫자값(연속값)을 반환한다.

* 선형 회귀의 종류
  - 일반 선형 회귀 : 예측값과 실제값의 RSS (Residual Sum of Squares)를 최소화할 수 있도록 회귀 계수를 최적화하며, 규제(Regularization)를 적용하지 않는 모델이다.
  - 릿지(Ridge) : 릿지 회귀는 선형 회귀에 L2 규제를 추가한 회귀 모델이다.
  - 라쏘(Lasso) : 라쏘 회귀는 선형 회귀에 L1 규제를 적용한 방식이다.
  - 엘라스틱넷(ElasticNet) : L2, L1 규제를 함께 결합한 모델이다.
  - 로지스틱 회귀(Logistic Regression) : 로지스틱 회귀는 회귀라는 이름이 붙어 있지만, 분류에 사용되는 선형 모델이다. 이산값을 예측한다. 특히, 이진 분류에 많이 사용된다.  



## 1. 회귀 비용함수 RSS와 경사하강법  


* 정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표이다. 하지만 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지 않는다.  
 


## 2. Linear Regression - 선형 회귀  

* **TN (True Negative)** : 예측을 Negative로 했는데, 맞은 것 (True) - 실제는 Negative  


## 3. Polynomial Regression - 다항 회귀  


## 4. Regularized Linear Regression - 규제 선형 회귀  


## 5. Logistic Regression - 로지스틱 회귀


## 6. 회귀 트리
