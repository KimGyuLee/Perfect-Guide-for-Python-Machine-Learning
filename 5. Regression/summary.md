# Regression

## Intro
회귀는 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법이다. 회귀는 지도 학습에서 가장 많이 활용되며, 주로 수치 데이터를 활용하는 기업의 데이터 분석에서 많이 사용된다.
머신러닝 회귀 예측의 핵심은 주어진 피처(독립 변수)와 결정 값 데이터(종속 변수) 기반에서 학습을 통해 최적의 회귀 계수를 찾아내는 것이다.

회귀는 회귀계수가 선형이면 선형 회귀, 선형이 아니면 비선형 회귀로 분류된다. 또한, 독립변수의 개수가 한 개이면 단일 회귀, 여러 개이면 다중 회귀로 나뉜다. 일반적으로 정형 데이터일 경우, 선형 회귀가 비선형회귀보다 예측 성능이 좋다.

최적의 회귀 모델을 만든다는 것은 전체 데이터의 잔차(오류 값) 합이 최소가 되는 모델을 만드는 것이다. 동시에 오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다는 의미이기도 하다.

Classification은 Category 값 (이산값)을 결과값으로 반환하고, Regression은 숫자값(연속값)을 반환한다.

* 선형 회귀의 종류
  - 일반 선형 회귀 : 예측값과 실제값의 RSS (Residual Sum of Squares)를 최소화할 수 있도록 회귀 계수를 최적화하며, 규제(Regularization)를 적용하지 않는 모델이다.
  - 릿지(Ridge) : 릿지 회귀는 선형 회귀에 L2 규제를 추가한 회귀 모델이다.
  - 라쏘(Lasso) : 라쏘 회귀는 선형 회귀에 L1 규제를 적용한 방식이다.
  - 엘라스틱넷(ElasticNet) : L2, L1 규제를 함께 결합한 모델이다.
  - 로지스틱 회귀(Logistic Regression) : 로지스틱 회귀는 회귀라는 이름이 붙어 있지만, 분류에 사용되는 선형 모델이다. 이산값을 예측한다. 특히, 이진 분류에 많이 사용된다.  


## 1. 회귀 비용함수 RSS와 경사하강법   
* **RSS (Residual Sum of Squares)** : 오류 값의 제곱을 구해서 더하는 방식이다.  
  - RSS를 최소로 하는 회귀 계수를 학습을 통해서 찾는 것이 머신러닝 기반 회귀의 핵심 사항이다.
  - RSS는 회귀식의 독깁변수 X, 종속변수 Y가 중심 변수가 아니라 W 변수 (회귀 계수)가 중심 변수임을 인지하는 것이 매우 중요하다. (학습 데이터로 입력되는 독립 변수와 종속 변수는 RSS에서 모두 상수로 간주한다.)
  - 일반적으로 RSS는 학습 데이터의 건수로 나누어서 다음과 같이 정규화된 식으로 표현된다.
  - 회귀에서 이 RSS를 비용 함수(Cost function)로 지칭한다. 머신러닝은 RSS, 즉 비용을 계속 줄이는 방향으로 데이터를 학습한다. 최종적으로는 RSS가 더 이상 감소하지 않는 최소의 오류 값을 구하게 되고, 이 때 최적의 예측 모델이 만들어 진다.  

![RSS](https://user-images.githubusercontent.com/58073455/73270653-6d66db00-4222-11ea-8d70-6f315594a14f.PNG)

  
* **경사하강법 (Gradient Descent)** : W 파라미터의 개수가 적다면 고차원 방정식으로 비용 함수가 최소가 되는 W 변수값을 도출할 수 있지만, W 파라미터가 많으면 고차원 방정식을 동원하더라도 해결하기 어렵다. 경사 하강법은 이러한 고차원 방정식에 대한 문제를 해결해주면서 비용 함수 RSS를 최소화하는 방법을 직관적으로 제공하는 방식이다.  
  - 점진적으로 반복적인 계산을 통해 W 파라미터 값을 업데이트하면서 오류 값이 최소가 되는 W 파라미터를 구하는 방식이다.
  - 경사 하강법은 반복적으로 비용 함수의 반환 값, 즉 예측값과 실제 값의 차이가 작아지는 방향성을 가지고 W 파라미터를 지속해서 보정해 나간다.
  - 오류 값이 더 이상 작아지지 않으면 그 오류 값을 최소 비용으로 판단하고 그 때의 W 값을 최적 파라미터로 반환한다.
  - 경사 하강법의 핵심은 '어떻게 하면 오류가 작아지는 방향으로 W 값을 보정할 수 있는가'이다.
  
  

## 2. Linear Regression - 선형 회귀  

* **TN (True Negative)** : 예측을 Negative로 했는데, 맞은 것 (True) - 실제는 Negative  


## 3. Polynomial Regression - 다항 회귀  


## 4. Regularized Linear Regression - 규제 선형 회귀  



## 5. Logistic Regression - 로지스틱 회귀


## 6. 회귀 트리
